
CREATE QUERY knn_cosine_cv_sub (VERTEX source, SET<STRING> e_type, SET<STRING> re_type, STRING v_label, STRING weight, INT max_k) RETURNS (ListAccum<STRING>) {
/* This subquery returns a list of predicted label for a source vertex with respect to different k within a given range. 
*/ 
        TYPEDEF TUPLE <label STRING, similarity FLOAT> Label_Score;
        HeapAccum<Label_Score>(max_k, similarity DESC) @@top_labels_heap;  # heap stores the (label, similarity) tuple, order by similarity score
        SumAccum<FLOAT> @numerator, @@norm1, @norm2, @similarity;
        MapAccum<STRING, INT> @@count;
        ListAccum<STRING> @@predicted_label_lists;  # list of predicted labels to return
        INT max_count = 0;
        STRING predicted_label;   # predicted label in each iteration
        INT k;

        # calculate similarity and find the top k nearest neighbors
        start = {source};
        subjects = SELECT t
                   FROM start:s -(e_type:e)-> :t
                   ACCUM t.@numerator = e.getAttr(weight, "FLOAT"),
                         @@norm1 += pow(e.getAttr(weight, "FLOAT"), 2);

        neighbours = SELECT t
                     FROM subjects:s -(re_type:e)-> :t
                     WHERE t != source AND t.getAttr(v_label, "STRING") != ""    # only consider the neighbors with known label
                     ACCUM t.@numerator += s.@numerator * e.getAttr(weight, "FLOAT");

        kNN = SELECT s
              FROM neighbours:s -(e_type:e)-> :t
              ACCUM s.@norm2 += pow(e.getAttr(weight, "FLOAT"), 2)
              POST-ACCUM @@top_labels_heap += Label_Score(s.getAttr(v_label, "STRING"), s.@numerator/sqrt(@@norm1 * s.@norm2)); # store the label and similarity score in a heap 

	# iterate the heap and calculate label count for different k
        k = 1;
        FOREACH item IN @@top_labels_heap DO  
                @@count += (item.label -> 1);   # count is a map, key is the label, value is the count of the label
                IF @@count.get(item.label) > max_count THEN
                         max_count = @@count.get(item.label);
                         predicted_label = item.label;
                END;
		@@predicted_label_lists += predicted_label;  # list of predicted labels
                k = k+1;
        END;
      
        PRINT @@predicted_label_lists;
        RETURN @@predicted_label_lists;
}


CREATE QUERY knn_cosine_cv (SET<STRING> v_type, SET<STRING> e_type, SET<STRING> re_type, STRING weight, STRING label, INT min_k, INT max_k) RETURNS (INT){
/* Leave-one-out cross validation for selecting optimal k. 
   The input is a range of k, output is the k with highest correct prediction rate.
   Note: When one vertex has no neighbor with known label, the prediction is considered false
*/
        ListAccum<FLOAT> @@correct_rate_list; 
        ListAccum<INT> @is_correct_list; 
        ListAccum<STRING> @predicted_label_list;
        SumAccum<FLOAT> @@total_score;
        INT n, k, best_k=1;
        FLOAT max_rate=0;
  
        IF max_k < min_k OR max_k < 1 THEN  // terminate if the range is invalid
                RETURN 0;
        END;
        start = {v_type};
  
        start = SELECT s
                FROM start:s 
                WHERE s.getAttr(label, "STRING") != ""  // get the vertices with known label
                ACCUM s.@predicted_label_list = knn_cosine_cv_sub(s, e_type, re_type, label, weight, max_k)  // get a list of predicted label wrt different k
                POST-ACCUM FOREACH pred_label IN s.@predicted_label_list DO
                                   IF s.getAttr(label, "STRING") == pred_label THEN  # *vStrAttrOld*  means no neighbor with label
                                           s.@is_correct_list += 1
                                   ELSE
                                           s.@is_correct_list += 0
                                   END                   
                           END;
  
	n = start.size();
        k = min_k-1;  # index starts from 0
        WHILE k < max_k DO
                @@total_score = 0;
                start = SELECT s
                        FROM start:s 
                        ACCUM IF s.@is_correct_list.size()==0 THEN
                                      @@total_score += 0  # if there is no neighbor, it is considered incorrect prediction
                              ELSE IF k >= s.@is_correct_list.size() THEN
                                      @@total_score += s.@is_correct_list.get(s.@is_correct_list.size()-1)   # use all neighbors it has when it is not enough  
                              ELSE 
                                      @@total_score += s.@is_correct_list.get(k)
                              END;
                @@correct_rate_list += @@total_score / n;
                IF @@total_score / n > max_rate THEN
                        max_rate = @@total_score / n;  # store the max correct rate in max_rate
                        best_k = k+1;
                END;
                k = k+1;
        END;

        PRINT @@correct_rate_list;
        PRINT best_k;
        RETURN best_k;
}
